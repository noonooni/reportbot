import requests
from bs4 import BeautifulSoup
import os
import re

TOKEN = os.environ['TELEGRAM_TOKEN']
CHAT_ID = os.environ['TELEGRAM_CHAT_ID']
URL = "http://snusmic.com/research/"

def send_message(text):
    api_url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    params = {'chat_id': CHAT_ID, 'text': text, 'parse_mode': 'HTML'}
    requests.get(api_url, params=params)

def fetch_top_5():
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(URL, headers=headers, timeout=30)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 1. ëª¨ë“  ê²Œì‹œê¸€ ë°•ìŠ¤(article)ë¥¼ ë¨¼ì € ì°¾ìŠµë‹ˆë‹¤.
        # ì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ elementor-post í´ë˜ìŠ¤ê°€ ê° ê²Œì‹œê¸€ì˜ ë‹¨ìœ„ì…ë‹ˆë‹¤.
        articles = soup.find_all('article', class_=re.compile(r'elementor-post'))
        
        post_list = []
        
        for article in articles:
            # a) ì œëª© ì°¾ê¸°: h3 ë‚´ë¶€ì˜ a íƒœê·¸ í˜¹ì€ article ë‚´ë¶€ì˜ ì²« ë²ˆì§¸ ìœ ì˜ë¯¸í•œ a íƒœê·¸
            title_tag = article.find('h3') or article.find('a')
            if not title_tag: continue
            
            title = title_tag.get_text().strip()
            link = ""
            
            # b) ë§í¬ ì°¾ê¸°
            link_tag = article.find('a')
            if link_tag:
                link = link_tag.get('href', '')
            
            # c) ë¶ˆí•„ìš”í•œ ê³µë°±ì´ë‚˜ ë©”ë‰´ ë°©ì§€ (ì œëª©ì´ 4ì ì´ìƒì¸ ê²ƒë§Œ)
            if len(title) > 3 and link.startswith('http'):
                if title not in [p['title'] for p in post_list]:
                    post_list.append({'title': title, 'link': link})
            
            if len(post_list) >= 5: break

        # 2. ê²°ê³¼ ì „ì†¡
        if post_list:
            result_text = "<b>ğŸ” SMIC Research ìµœì‹  ê²Œì‹œë¬¼</b>\n\n"
            for i, post in enumerate(post_list):
                result_text += f"{i+1}. <b>{post['title']}</b>\nğŸ”— <a href='{post['link']}'>ê²Œì‹œê¸€ë¡œ ì´ë™</a>\n\n"
            send_message(result_text)
        else:
            # 3. ìµœí›„ì˜ ìˆ˜ë‹¨: ì†ŒìŠ¤ì½”ë“œ ë‚´ ëª¨ë“  ë§í¬ ì¤‘ 'portfolio'ë‚˜ 'research' ë‹¨ì–´ê°€ ë“¤ì–´ê°„ ì œëª© ìˆëŠ” ë§í¬ ì¶”ì¶œ
            all_links = soup.find_all('a')
            for a in all_links:
                t = a.get_text().strip()
                l = a.get('href', '')
                if len(t) > 10 and ('/research/' in l or '/portfolio/' in l):
                    if t not in [p['title'] for p in post_list]:
                        post_list.append({'title': t, 'link': l})
                if len(post_list) >= 5: break
            
            if post_list:
                result_text = "<b>ğŸ” SMIC ê²Œì‹œë¬¼ (ëŒ€ì²´ íƒìƒ‰ ì„±ê³µ)</b>\n\n"
                for i, post in enumerate(post_list):
                    result_text += f"{i+1}. <b>{post['title']}</b>\nğŸ”— {post['link']}\n\n"
                send_message(result_text)
            else:
                send_message("âŒ ê²Œì‹œê¸€ ì¶”ì¶œ ì‹¤íŒ¨. ì‚¬ì´íŠ¸ê°€ ì½˜í…ì¸ ë¥¼ ìˆ¨ê¸°ê³  ìˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        send_message(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    fetch_top_5()
