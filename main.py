import requests
from bs4 import BeautifulSoup
import os

TOKEN = os.environ['TELEGRAM_TOKEN']
CHAT_ID = os.environ['TELEGRAM_CHAT_ID']
URL = "http://snusmic.com/research/"

def send_message(text):
    api_url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    params = {'chat_id': CHAT_ID, 'text': text, 'parse_mode': 'HTML'}
    requests.get(api_url, params=params)

def fetch_top_5():
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(URL, headers=headers, timeout=30)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 1. 'Portfolio' ìœ„ì ¯ì˜ ê° ì•„ì´í…œ ë©ì–´ë¦¬ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜µë‹ˆë‹¤.
        items = soup.select('.elementor-portfolio-item')
        
        post_list = []
        for item in items:
            # ì œëª© ì¶”ì¶œ: ì œëª©ì„ ë‹´ê³  ìˆëŠ” í´ë˜ìŠ¤ë¥¼ ì •ë°€ íƒ€ê²ŸíŒ…í•©ë‹ˆë‹¤.
            title_tag = item.select_one('.elementor-portfolio-item__title')
            # ë§í¬ ì¶”ì¶œ: ì•„ì´í…œ ìì²´ í˜¹ì€ ë‚´ë¶€ì˜ a íƒœê·¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            link_tag = item.select_one('a')
            
            if title_tag and link_tag:
                title = title_tag.get_text(strip=True)
                link = link_tag.get('href', '')
                
                # ì¤‘ë³µ ë°©ì§€ ë° ìœ íš¨ì„± ê²€ì‚¬
                if title and link.startswith('http') and title not in [p['title'] for p in post_list]:
                    post_list.append({'title': title, 'link': link})
            
            if len(post_list) >= 5: break

        # 2. ê²°ê³¼ ì „ì†¡
        if post_list:
            result_text = "<b>ğŸ” SMIC Research ìµœì‹  ë¦¬ìŠ¤íŠ¸</b>\n\n"
            for i, p in enumerate(post_list):
                result_text += f"{i+1}. <b>{p['title']}</b>\nğŸ”— <a href='{p['link']}'>ë³´ê³ ì„œ ë³´ê¸°</a>\n\n"
            send_message(result_text)
        else:
            # ë°±ì—… ëª¨ë“œ: í´ë˜ìŠ¤ëª…ì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ íŒ¨í„´ìœ¼ë¡œ ê°•ì œ íƒìƒ‰
            backup_links = soup.find_all('a', href=True)
            for a in backup_links:
                href = a['href']
                text = a.get_text(strip=True)
                # ì—°êµ¬ê¸€ì¼ í™•ë¥ ì´ ë†’ì€ ë§í¬ íŒ¨í„´ í•„í„°ë§
                if '/research/' in href and len(text) > 10:
                    if text not in [p['title'] for p in post_list]:
                        post_list.append({'title': text, 'link': href})
                if len(post_list) >= 5: break
            
            if post_list:
                result_text = "<b>ğŸ” SMIC Research (íŒ¨í„´ íƒìƒ‰ ì„±ê³µ)</b>\n\n"
                for i, p in enumerate(post_list):
                    result_text += f"{i+1}. <b>{p['title']}</b>\nğŸ”— {p['link']}\n\n"
                send_message(result_text)
            else:
                send_message("âŒ ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ ë¡œë”© êµ¬ì¡°ê°€ ì¼ë°˜ì ì¸ í¬ë¡¤ë§ì„ í—ˆìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    except Exception as e:
        send_message(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    fetch_top_5()
